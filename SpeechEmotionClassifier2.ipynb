{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc77860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4695e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing labels of the files\n",
    "labels = os.listdir(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbb57ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-02-01-01-01-06.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3530447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load(f\"Data/{labels[1]}\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849f8bf",
   "metadata": {},
   "source": [
    "## Extract emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84b08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = np.array([label.split(\"-\")[2] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18d54c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['02', '02', '02', '02', '02'], dtype='<U2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253adbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filename):\n",
    "    audio, sample_rate = librosa.load(filename, res_type=\"kaiser_fast\")\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8605da",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for label in labels:\n",
    "    filename = f\"Data/{label}\"\n",
    "    \n",
    "    emotion = label.split(\"-\")[2]\n",
    "    data = extract_features(filename)\n",
    "    features.append([data, emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a7b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.66113403e+02,  5.62173576e+01, -7.56887484e+00,  1.57707405e+01,\n",
       "        -8.45027637e+00,  1.83744097e+00, -6.82167864e+00, -4.37701273e+00,\n",
       "        -5.91381168e+00,  5.17688990e-01, -5.59894037e+00, -2.13708138e+00,\n",
       "        -6.38166094e+00,  2.84868383e+00, -6.89996719e+00, -1.23033297e+00,\n",
       "        -4.16035271e+00, -1.37664831e+00, -4.97348595e+00, -1.35401809e+00,\n",
       "        -2.00252700e+00, -2.14882398e+00, -1.11055171e+00, -2.46265188e-01,\n",
       "        -1.22439280e-01,  4.77262735e-01,  4.27485657e+00,  4.82439423e+00,\n",
       "         7.54139376e+00,  4.93660450e+00,  3.66524744e+00,  3.25066614e+00,\n",
       "         2.14365625e+00,  3.23849964e+00,  2.43824267e+00,  2.52844048e+00,\n",
       "        -3.09295207e-01,  9.82488215e-01,  1.01983917e+00,  5.99840820e-01],\n",
       "       dtype=float32),\n",
       " '02']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0450a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features, columns=[\"feature\", \"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3d6298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-729.98016, 66.51589, -0.9419843, 19.070974, ...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-666.1134, 56.217358, -7.568875, 15.7707405, ...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-639.27637, 69.9923, 0.7942198, 17.575535, 1....</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-663.54083, 56.19745, -15.152023, 8.111385, -...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-734.74243, 77.852264, 6.6088023, 23.579966, ...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature emotion\n",
       "0  [-729.98016, 66.51589, -0.9419843, 19.070974, ...      02\n",
       "1  [-666.1134, 56.217358, -7.568875, 15.7707405, ...      02\n",
       "2  [-639.27637, 69.9923, 0.7942198, 17.575535, 1....      02\n",
       "3  [-663.54083, 56.19745, -15.152023, 8.111385, -...      02\n",
       "4  [-734.74243, 77.852264, 6.6088023, 23.579966, ...      02"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba7d202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(features_df['feature'].tolist())\n",
    "y=np.array(features_df['emotion'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68b70c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 40), (960,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8c4aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['02', '02', '02', '02', '02', '02', '02', '02', '02', '02'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5594c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71467716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b30e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c5bc5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.9474713e+02,  5.5160381e+01, -2.5127358e+00, ...,\n",
       "        -7.3903787e-01, -1.9837615e+00, -1.2665052e+00],\n",
       "       [-8.0673053e+02,  4.5237591e+01, -5.5813923e+00, ...,\n",
       "         2.7756355e+00,  5.9816724e-01,  5.2687460e-01],\n",
       "       [-6.1684766e+02,  8.1195053e+01, -6.6228852e+00, ...,\n",
       "         2.4592552e+00, -1.2701117e+00, -6.9109130e-01],\n",
       "       ...,\n",
       "       [-5.8245581e+02,  4.5947723e+01, -2.5991879e+01, ...,\n",
       "        -7.8162730e-01,  1.3410363e+00,  1.9998642e+00],\n",
       "       [-6.3795978e+02,  7.1686310e+01, -6.8877344e+00, ...,\n",
       "         4.0222698e-01, -1.3108990e+00,  5.2045202e-01],\n",
       "       [-3.6642828e+02,  2.3118233e+01, -1.6935003e+01, ...,\n",
       "         2.2547913e-01,  1.0447268e+00,  3.1393673e+00]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605806b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba77901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 40), (768, 5), (192, 40), (192, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01cc22",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3db58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e317f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ecfa95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 505       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,905\n",
      "Trainable params: 44,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2b6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cabc466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/24 [>.............................] - ETA: 26s - loss: 150.9099 - accuracy: 0.1250\n",
      "Epoch 00001: val_loss improved from inf to 7.72853, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 2s 16ms/step - loss: 71.0830 - accuracy: 0.2031 - val_loss: 7.7285 - val_accuracy: 0.2656\n",
      "Epoch 2/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 46.2728 - accuracy: 0.3125\n",
      "Epoch 00002: val_loss improved from 7.72853 to 2.82045, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 34.6958 - accuracy: 0.2005 - val_loss: 2.8204 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 16.5913 - accuracy: 0.3125\n",
      "Epoch 00003: val_loss improved from 2.82045 to 1.66425, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 20.5658 - accuracy: 0.2083 - val_loss: 1.6643 - val_accuracy: 0.2344\n",
      "Epoch 4/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 14.9461 - accuracy: 0.2812\n",
      "Epoch 00004: val_loss improved from 1.66425 to 1.60716, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.6959 - accuracy: 0.1862 - val_loss: 1.6072 - val_accuracy: 0.2292\n",
      "Epoch 5/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 8.7397 - accuracy: 0.1562\n",
      "Epoch 00005: val_loss did not improve from 1.60716\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 9.1897 - accuracy: 0.2031 - val_loss: 1.6131 - val_accuracy: 0.2083\n",
      "Epoch 6/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 5.1211 - accuracy: 0.2812\n",
      "Epoch 00006: val_loss did not improve from 1.60716\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.3913 - accuracy: 0.1888 - val_loss: 1.6072 - val_accuracy: 0.2135\n",
      "Epoch 7/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 4.5239 - accuracy: 0.3750\n",
      "Epoch 00007: val_loss improved from 1.60716 to 1.60702, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3362 - accuracy: 0.2005 - val_loss: 1.6070 - val_accuracy: 0.2135\n",
      "Epoch 8/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 5.3800 - accuracy: 0.1250\n",
      "Epoch 00008: val_loss improved from 1.60702 to 1.60686, saving model to ./saveModel\\audio_classification2.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5298 - accuracy: 0.1823 - val_loss: 1.6069 - val_accuracy: 0.2135\n",
      "Epoch 9/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 3.4816 - accuracy: 0.2188\n",
      "Epoch 00009: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.6619 - accuracy: 0.2305 - val_loss: 1.6072 - val_accuracy: 0.2135\n",
      "Epoch 10/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 3.6277 - accuracy: 0.2500\n",
      "Epoch 00010: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 3.1800 - accuracy: 0.1888 - val_loss: 1.6072 - val_accuracy: 0.2135\n",
      "Epoch 11/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 3.1750 - accuracy: 0.1562\n",
      "Epoch 00011: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.8969 - accuracy: 0.1927 - val_loss: 1.6072 - val_accuracy: 0.2135\n",
      "Epoch 12/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.9932 - accuracy: 0.1875\n",
      "Epoch 00012: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.4564 - accuracy: 0.2044 - val_loss: 1.6073 - val_accuracy: 0.2135\n",
      "Epoch 13/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8400 - accuracy: 0.0938\n",
      "Epoch 00013: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.2675 - accuracy: 0.2070 - val_loss: 1.6075 - val_accuracy: 0.2135\n",
      "Epoch 14/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8543 - accuracy: 0.2188\n",
      "Epoch 00014: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.1137 - accuracy: 0.1875 - val_loss: 1.6075 - val_accuracy: 0.2135\n",
      "Epoch 15/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8329 - accuracy: 0.2500\n",
      "Epoch 00015: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 2.1299 - accuracy: 0.2083 - val_loss: 1.6076 - val_accuracy: 0.2135\n",
      "Epoch 16/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 1.9384 - accuracy: 0.2174\n",
      "Epoch 00016: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.9443 - accuracy: 0.2148 - val_loss: 1.6079 - val_accuracy: 0.2135\n",
      "Epoch 17/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 2.4793 - accuracy: 0.1562\n",
      "Epoch 00017: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8252 - accuracy: 0.2161 - val_loss: 1.6080 - val_accuracy: 0.2135\n",
      "Epoch 18/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 2.2679 - accuracy: 0.0938\n",
      "Epoch 00018: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8559 - accuracy: 0.1953 - val_loss: 1.6084 - val_accuracy: 0.2135\n",
      "Epoch 19/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.9969 - accuracy: 0.2500\n",
      "Epoch 00019: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.8658 - accuracy: 0.1992 - val_loss: 1.6086 - val_accuracy: 0.2135\n",
      "Epoch 20/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 2.1072 - accuracy: 0.1250\n",
      "Epoch 00020: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7579 - accuracy: 0.1940 - val_loss: 1.6088 - val_accuracy: 0.2135\n",
      "Epoch 21/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6833 - accuracy: 0.2500\n",
      "Epoch 00021: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8336 - accuracy: 0.2018 - val_loss: 1.6091 - val_accuracy: 0.2135\n",
      "Epoch 22/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7091 - accuracy: 0.1562\n",
      "Epoch 00022: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7503 - accuracy: 0.1992 - val_loss: 1.6093 - val_accuracy: 0.2135\n",
      "Epoch 23/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5290 - accuracy: 0.2812\n",
      "Epoch 00023: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7404 - accuracy: 0.1901 - val_loss: 1.6094 - val_accuracy: 0.2135\n",
      "Epoch 24/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7942 - accuracy: 0.1875\n",
      "Epoch 00024: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6994 - accuracy: 0.1953 - val_loss: 1.6097 - val_accuracy: 0.2135\n",
      "Epoch 25/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6368 - accuracy: 0.1250\n",
      "Epoch 00025: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.7210 - accuracy: 0.2070 - val_loss: 1.6100 - val_accuracy: 0.2135\n",
      "Epoch 26/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6222 - accuracy: 0.2812\n",
      "Epoch 00026: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.7438 - accuracy: 0.2005 - val_loss: 1.6102 - val_accuracy: 0.2135\n",
      "Epoch 27/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6262 - accuracy: 0.2188\n",
      "Epoch 00027: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.7644 - accuracy: 0.1966 - val_loss: 1.6104 - val_accuracy: 0.2135\n",
      "Epoch 28/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8335 - accuracy: 0.1875\n",
      "Epoch 00028: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6775 - accuracy: 0.1953 - val_loss: 1.6106 - val_accuracy: 0.2135\n",
      "Epoch 29/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7589 - accuracy: 0.1562\n",
      "Epoch 00029: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.7087 - accuracy: 0.1992 - val_loss: 1.6109 - val_accuracy: 0.2135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6332 - accuracy: 0.2500\n",
      "Epoch 00030: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6768 - accuracy: 0.1914 - val_loss: 1.6110 - val_accuracy: 0.2135\n",
      "Epoch 31/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6283 - accuracy: 0.1562\n",
      "Epoch 00031: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6849 - accuracy: 0.1758 - val_loss: 1.6114 - val_accuracy: 0.1406\n",
      "Epoch 32/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6113 - accuracy: 0.2812\n",
      "Epoch 00032: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6626 - accuracy: 0.2161 - val_loss: 1.6115 - val_accuracy: 0.1406\n",
      "Epoch 33/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6408 - accuracy: 0.2500\n",
      "Epoch 00033: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6436 - accuracy: 0.2227 - val_loss: 1.6119 - val_accuracy: 0.1406\n",
      "Epoch 34/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8226 - accuracy: 0.1875\n",
      "Epoch 00034: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.7059 - accuracy: 0.2057 - val_loss: 1.6121 - val_accuracy: 0.1406\n",
      "Epoch 35/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6409 - accuracy: 0.1875\n",
      "Epoch 00035: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6559 - accuracy: 0.2122 - val_loss: 1.6123 - val_accuracy: 0.1406\n",
      "Epoch 36/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6140 - accuracy: 0.1250\n",
      "Epoch 00036: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6351 - accuracy: 0.2188 - val_loss: 1.6126 - val_accuracy: 0.1406\n",
      "Epoch 37/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6323 - accuracy: 0.2812\n",
      "Epoch 00037: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6250 - accuracy: 0.2161 - val_loss: 1.6128 - val_accuracy: 0.1406\n",
      "Epoch 38/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6446 - accuracy: 0.1250\n",
      "Epoch 00038: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6488 - accuracy: 0.2135 - val_loss: 1.6131 - val_accuracy: 0.1406\n",
      "Epoch 39/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6158 - accuracy: 0.2500\n",
      "Epoch 00039: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.2070 - val_loss: 1.6133 - val_accuracy: 0.1406\n",
      "Epoch 40/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6313 - accuracy: 0.1250\n",
      "Epoch 00040: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6546 - accuracy: 0.2227 - val_loss: 1.6135 - val_accuracy: 0.1406\n",
      "Epoch 41/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6778 - accuracy: 0.2812\n",
      "Epoch 00041: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6527 - accuracy: 0.2109 - val_loss: 1.6137 - val_accuracy: 0.1406\n",
      "Epoch 42/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5893 - accuracy: 0.2500\n",
      "Epoch 00042: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6290 - accuracy: 0.2214 - val_loss: 1.6138 - val_accuracy: 0.1406\n",
      "Epoch 43/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6324 - accuracy: 0.2188\n",
      "Epoch 00043: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6350 - accuracy: 0.2109 - val_loss: 1.6137 - val_accuracy: 0.1406\n",
      "Epoch 44/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6233 - accuracy: 0.1875\n",
      "Epoch 00044: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6511 - accuracy: 0.2188 - val_loss: 1.6141 - val_accuracy: 0.1406\n",
      "Epoch 45/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5994 - accuracy: 0.1875\n",
      "Epoch 00045: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6519 - accuracy: 0.2201 - val_loss: 1.6143 - val_accuracy: 0.1406\n",
      "Epoch 46/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5991 - accuracy: 0.3750\n",
      "Epoch 00046: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6123 - accuracy: 0.2161 - val_loss: 1.6144 - val_accuracy: 0.1406\n",
      "Epoch 47/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6209 - accuracy: 0.0938\n",
      "Epoch 00047: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6198 - accuracy: 0.2148 - val_loss: 1.6144 - val_accuracy: 0.1406\n",
      "Epoch 48/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6035 - accuracy: 0.3125\n",
      "Epoch 00048: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6372 - accuracy: 0.2148 - val_loss: 1.6146 - val_accuracy: 0.1406\n",
      "Epoch 49/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5761 - accuracy: 0.2500\n",
      "Epoch 00049: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6403 - accuracy: 0.2188 - val_loss: 1.6146 - val_accuracy: 0.1406\n",
      "Epoch 50/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7156 - accuracy: 0.2188\n",
      "Epoch 00050: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6569 - accuracy: 0.2135 - val_loss: 1.6146 - val_accuracy: 0.1406\n",
      "Epoch 51/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6138 - accuracy: 0.1250\n",
      "Epoch 00051: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6483 - accuracy: 0.2161 - val_loss: 1.6148 - val_accuracy: 0.1406\n",
      "Epoch 52/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.8428 - accuracy: 0.0938\n",
      "Epoch 00052: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6499 - accuracy: 0.2096 - val_loss: 1.6150 - val_accuracy: 0.1406\n",
      "Epoch 53/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5980 - accuracy: 0.2500\n",
      "Epoch 00053: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6349 - accuracy: 0.2161 - val_loss: 1.6151 - val_accuracy: 0.1406\n",
      "Epoch 54/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6026 - accuracy: 0.2500\n",
      "Epoch 00054: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6278 - accuracy: 0.2148 - val_loss: 1.6151 - val_accuracy: 0.1406\n",
      "Epoch 55/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6047 - accuracy: 0.1875\n",
      "Epoch 00055: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6153 - accuracy: 0.2227 - val_loss: 1.6150 - val_accuracy: 0.1406\n",
      "Epoch 56/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6189 - accuracy: 0.1875\n",
      "Epoch 00056: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6380 - accuracy: 0.2109 - val_loss: 1.6153 - val_accuracy: 0.1406\n",
      "Epoch 57/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.6231 - accuracy: 0.2094\n",
      "Epoch 00057: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.6240 - accuracy: 0.2096 - val_loss: 1.6155 - val_accuracy: 0.1406\n",
      "Epoch 58/100\n",
      "20/24 [========================>.....] - ETA: 0s - loss: 1.6172 - accuracy: 0.2234\n",
      "Epoch 00058: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6147 - accuracy: 0.2161 - val_loss: 1.6158 - val_accuracy: 0.1406\n",
      "Epoch 59/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6957 - accuracy: 0.2500\n",
      "Epoch 00059: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6500 - accuracy: 0.2135 - val_loss: 1.6157 - val_accuracy: 0.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "17/24 [====================>.........] - ETA: 0s - loss: 1.6359 - accuracy: 0.2188\n",
      "Epoch 00060: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6245 - accuracy: 0.2161 - val_loss: 1.6157 - val_accuracy: 0.1406\n",
      "Epoch 61/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6042 - accuracy: 0.2500\n",
      "Epoch 00061: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6062 - accuracy: 0.2122 - val_loss: 1.6158 - val_accuracy: 0.1406\n",
      "Epoch 62/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.9954 - accuracy: 0.3438\n",
      "Epoch 00062: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6487 - accuracy: 0.2122 - val_loss: 1.6160 - val_accuracy: 0.1406\n",
      "Epoch 63/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5860 - accuracy: 0.2500\n",
      "Epoch 00063: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6182 - accuracy: 0.2161 - val_loss: 1.6159 - val_accuracy: 0.1406\n",
      "Epoch 64/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6208 - accuracy: 0.2188\n",
      "Epoch 00064: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6183 - accuracy: 0.2161 - val_loss: 1.6159 - val_accuracy: 0.1406\n",
      "Epoch 65/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5938 - accuracy: 0.2812\n",
      "Epoch 00065: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6287 - accuracy: 0.2148 - val_loss: 1.6160 - val_accuracy: 0.1406\n",
      "Epoch 66/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6087 - accuracy: 0.2188\n",
      "Epoch 00066: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6147 - accuracy: 0.2201 - val_loss: 1.6161 - val_accuracy: 0.1406\n",
      "Epoch 67/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6961 - accuracy: 0.2500\n",
      "Epoch 00067: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6203 - accuracy: 0.2161 - val_loss: 1.6161 - val_accuracy: 0.1406\n",
      "Epoch 68/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6112 - accuracy: 0.3438\n",
      "Epoch 00068: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6138 - accuracy: 0.2148 - val_loss: 1.6161 - val_accuracy: 0.1406\n",
      "Epoch 69/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6184 - accuracy: 0.0625\n",
      "Epoch 00069: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6183 - accuracy: 0.2109 - val_loss: 1.6160 - val_accuracy: 0.1406\n",
      "Epoch 70/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.7470 - accuracy: 0.1250\n",
      "Epoch 00070: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6183 - accuracy: 0.2135 - val_loss: 1.6160 - val_accuracy: 0.1406\n",
      "Epoch 71/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5913 - accuracy: 0.3125\n",
      "Epoch 00071: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6169 - accuracy: 0.2148 - val_loss: 1.6162 - val_accuracy: 0.1406\n",
      "Epoch 72/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6028 - accuracy: 0.2500\n",
      "Epoch 00072: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6210 - accuracy: 0.2148 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 73/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6518 - accuracy: 0.1562\n",
      "Epoch 00073: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6217 - accuracy: 0.2122 - val_loss: 1.6162 - val_accuracy: 0.1406\n",
      "Epoch 74/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6119 - accuracy: 0.1875\n",
      "Epoch 00074: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6215 - accuracy: 0.2148 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 75/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5964 - accuracy: 0.2812\n",
      "Epoch 00075: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6289 - accuracy: 0.2188 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 76/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6010 - accuracy: 0.2812\n",
      "Epoch 00076: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6175 - accuracy: 0.2161 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 77/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6056 - accuracy: 0.2188\n",
      "Epoch 00077: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6184 - accuracy: 0.2148 - val_loss: 1.6166 - val_accuracy: 0.1406\n",
      "Epoch 78/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6042 - accuracy: 0.2500\n",
      "Epoch 00078: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6222 - accuracy: 0.2109 - val_loss: 1.6163 - val_accuracy: 0.1406\n",
      "Epoch 79/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6080 - accuracy: 0.2500\n",
      "Epoch 00079: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6168 - accuracy: 0.2135 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 80/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6470 - accuracy: 0.2500\n",
      "Epoch 00080: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6154 - accuracy: 0.2122 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 81/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6145 - accuracy: 0.0938\n",
      "Epoch 00081: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6247 - accuracy: 0.2122 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 82/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.5986 - accuracy: 0.3125\n",
      "Epoch 00082: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6140 - accuracy: 0.2161 - val_loss: 1.6166 - val_accuracy: 0.1406\n",
      "Epoch 83/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6075 - accuracy: 0.2500\n",
      "Epoch 00083: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6201 - accuracy: 0.2122 - val_loss: 1.6163 - val_accuracy: 0.1406\n",
      "Epoch 84/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6089 - accuracy: 0.2188\n",
      "Epoch 00084: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6248 - accuracy: 0.2109 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 85/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6161 - accuracy: 0.1562\n",
      "Epoch 00085: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6293 - accuracy: 0.2148 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 86/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6107 - accuracy: 0.2188\n",
      "Epoch 00086: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6171 - accuracy: 0.2201 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 87/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6092 - accuracy: 0.1875\n",
      "Epoch 00087: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6323 - accuracy: 0.2161 - val_loss: 1.6167 - val_accuracy: 0.1406\n",
      "Epoch 88/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6042 - accuracy: 0.2188\n",
      "Epoch 00088: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6082 - accuracy: 0.2148 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 89/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6042 - accuracy: 0.2500\n",
      "Epoch 00089: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6097 - accuracy: 0.2135 - val_loss: 1.6165 - val_accuracy: 0.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6123 - accuracy: 0.1250\n",
      "Epoch 00090: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6237 - accuracy: 0.2135 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 91/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6110 - accuracy: 0.2188\n",
      "Epoch 00091: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6094 - accuracy: 0.2122 - val_loss: 1.6163 - val_accuracy: 0.1406\n",
      "Epoch 92/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6029 - accuracy: 0.2812\n",
      "Epoch 00092: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6263 - accuracy: 0.2148 - val_loss: 1.6167 - val_accuracy: 0.1406\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.6176 - accuracy: 0.2161\n",
      "Epoch 00093: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6176 - accuracy: 0.2161 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 94/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6035 - accuracy: 0.2812\n",
      "Epoch 00094: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6096 - accuracy: 0.2148 - val_loss: 1.6165 - val_accuracy: 0.1406\n",
      "Epoch 95/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6156 - accuracy: 0.1562\n",
      "Epoch 00095: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6199 - accuracy: 0.2122 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 96/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6127 - accuracy: 0.2188\n",
      "Epoch 00096: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6080 - accuracy: 0.2161 - val_loss: 1.6166 - val_accuracy: 0.1406\n",
      "Epoch 97/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6128 - accuracy: 0.1875\n",
      "Epoch 00097: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6225 - accuracy: 0.2122 - val_loss: 1.6166 - val_accuracy: 0.1406\n",
      "Epoch 98/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6077 - accuracy: 0.2500\n",
      "Epoch 00098: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6059 - accuracy: 0.2161 - val_loss: 1.6166 - val_accuracy: 0.1406\n",
      "Epoch 99/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6106 - accuracy: 0.2188\n",
      "Epoch 00099: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6121 - accuracy: 0.2161 - val_loss: 1.6164 - val_accuracy: 0.1406\n",
      "Epoch 100/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.6072 - accuracy: 0.1875\n",
      "Epoch 00100: val_loss did not improve from 1.60686\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1.6127 - accuracy: 0.2135 - val_loss: 1.6168 - val_accuracy: 0.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea5db65e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./saveModel/audio_classification2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d7a5674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.140625"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "514920ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.640625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imported = tf.keras.models.load_model(\"savedModel/audio_classification2.hdf5\")\n",
    "\n",
    "test_accuracy=model_imported.evaluate(X_test,y_test,verbose=0)\n",
    "test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "139d2e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010416865348816"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imported2 = tf.keras.models.load_model(\"savedModel/audio_classification.hdf5\")\n",
    "\n",
    "test_accuracy=model_imported2.evaluate(X_test,y_test,verbose=0)\n",
    "test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ab682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8232a4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.10416865348816"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy in percentage\n",
    "accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb99129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
