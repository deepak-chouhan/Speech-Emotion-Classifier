{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8183e222",
   "metadata": {},
   "source": [
    "# Speech Emotion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41f3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143db4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0caa1",
   "metadata": {},
   "source": [
    "# DataSet\n",
    "\n",
    "We will be using **RAVDESS** dataset from kaggle https://www.kaggle.com/dmitrybabko/speech-emotion-recognition-en\n",
    "\n",
    "Here is the filename identifiers as per the official RAVDESS website:\n",
    "\n",
    "> - Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    ">  Vocal channel (01 = speech, 02 = song).\n",
    "> - Emotion \n",
    "    - 01 = neutral\n",
    "    - **02 = calm**\n",
    "    - **03 = happy**\n",
    "    - **04 = sad**\n",
    "    - **05 = angry**\n",
    "    - **06 = fearful**\n",
    "    - 07 = disgust\n",
    "    - 08 = surprised\n",
    "> - Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "> - Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "> - Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "> - Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. `02-01-06-01-02-01-12.wav` This means the meta data for the audio file is:\n",
    "\n",
    "> - Video-only (02)\n",
    "> - Speech (01)\n",
    "> - Fearful (06)\n",
    "> - Normal intensity (01)\n",
    "> - Statement \"dogs\" (02)\n",
    "> - 1st Repetition (01)\n",
    "> - 12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ed9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72342c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0057979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the emotions which are not necessary for us to predict\n",
    "\n",
    "# for label in labels:\n",
    "#     emotion = label.split(\"-\")[2]\n",
    "    \n",
    "#     if emotion == \"01\" or emotion == \"08\" or emotion == \"07\":\n",
    "#         os.remove(f\"Data/{label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973fefcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-02-01-01-01-02.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c34daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(f\"Data/{labels[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2adfa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fbbf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-02-01-01-01-01.wav'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da641b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the feelings\n",
    "labels[0].split(\"-\")[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72738b9",
   "metadata": {},
   "source": [
    "Now we need to make an array of feeling which will act as labels which we will predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3e9b1",
   "metadata": {},
   "source": [
    "## Emotion \n",
    "- 02 = calm\n",
    "- 03 = happy\n",
    "- 04 = sad\n",
    "- 05 = angry\n",
    "- 06 = fearful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a325c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [label.split(\"-\")[2] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3935e4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02', '02', '02', '02', '02']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1cfcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotions\n",
       "02          192\n",
       "03          192\n",
       "04          192\n",
       "05          192\n",
       "06          192\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(emotions, columns=[\"Emotions\"]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9aec1d",
   "metadata": {},
   "source": [
    "## Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996a6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_features = pd.DataFrame(columns=[\"features\"])\n",
    "indx = 0\n",
    "for filename in labels:\n",
    "    \n",
    "    X, sample_rate = librosa.load(f\"Data/{filename}\", duration=2.5, res_type='kaiser_fast')\n",
    "    # Convert sample_rate to numpy arra\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    mfccs_feature = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "    feature = np.mean(mfccs_feature.T, axis=0)\n",
    "    \n",
    "    df_features.loc[indx] = [feature]\n",
    "    indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77114379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-678.94885, 76.40213, -3.9693217, 24.48506, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-629.50836, 54.85913, -15.076416, 19.398994, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-610.4715, 60.676125, -6.567759, 22.445854, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-632.85834, 57.813908, -15.912763, 11.7422, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-705.80634, 72.26668, 5.6474605, 31.054544, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features\n",
       "0  [-678.94885, 76.40213, -3.9693217, 24.48506, 2...\n",
       "1  [-629.50836, 54.85913, -15.076416, 19.398994, ...\n",
       "2  [-610.4715, 60.676125, -6.567759, 22.445854, -...\n",
       "3  [-632.85834, 57.813908, -15.912763, 11.7422, -...\n",
       "4  [-705.80634, 72.26668, 5.6474605, 31.054544, 2..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2473b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x240c04471c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "librosa.display.waveplot(df_features['features'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a806b5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotions\n",
       "0       02\n",
       "1       02\n",
       "2       02\n",
       "3       02\n",
       "4       02"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame of emotions\n",
    "df_emotions = pd.DataFrame(emotions, columns=[\"emotions\"])\n",
    "df_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e37b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-678.948853</td>\n",
       "      <td>76.402130</td>\n",
       "      <td>-3.969322</td>\n",
       "      <td>24.485060</td>\n",
       "      <td>2.343696</td>\n",
       "      <td>5.315933</td>\n",
       "      <td>-10.401676</td>\n",
       "      <td>-0.682352</td>\n",
       "      <td>-17.013817</td>\n",
       "      <td>-3.063685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.363485</td>\n",
       "      <td>-2.531532</td>\n",
       "      <td>-1.793462</td>\n",
       "      <td>-4.022706</td>\n",
       "      <td>-1.577954</td>\n",
       "      <td>-1.587781</td>\n",
       "      <td>-1.696130</td>\n",
       "      <td>-2.855098</td>\n",
       "      <td>-3.651742</td>\n",
       "      <td>-4.129297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-629.508362</td>\n",
       "      <td>54.859131</td>\n",
       "      <td>-15.076416</td>\n",
       "      <td>19.398994</td>\n",
       "      <td>-13.276542</td>\n",
       "      <td>-0.163535</td>\n",
       "      <td>-8.997267</td>\n",
       "      <td>-4.458826</td>\n",
       "      <td>-9.508459</td>\n",
       "      <td>0.139021</td>\n",
       "      <td>...</td>\n",
       "      <td>5.524229</td>\n",
       "      <td>3.406778</td>\n",
       "      <td>3.029715</td>\n",
       "      <td>3.747022</td>\n",
       "      <td>2.242086</td>\n",
       "      <td>2.204940</td>\n",
       "      <td>-1.960129</td>\n",
       "      <td>-1.560523</td>\n",
       "      <td>-0.784178</td>\n",
       "      <td>-1.295257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-610.471497</td>\n",
       "      <td>60.676125</td>\n",
       "      <td>-6.567759</td>\n",
       "      <td>22.445854</td>\n",
       "      <td>-2.144975</td>\n",
       "      <td>2.539741</td>\n",
       "      <td>-20.668135</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>-7.860404</td>\n",
       "      <td>-4.285071</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.345382</td>\n",
       "      <td>-2.634505</td>\n",
       "      <td>-2.230956</td>\n",
       "      <td>-0.879381</td>\n",
       "      <td>-1.582407</td>\n",
       "      <td>-1.810162</td>\n",
       "      <td>-3.177479</td>\n",
       "      <td>-5.062142</td>\n",
       "      <td>-3.402217</td>\n",
       "      <td>-2.151505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-632.858337</td>\n",
       "      <td>57.813908</td>\n",
       "      <td>-15.912763</td>\n",
       "      <td>11.742200</td>\n",
       "      <td>-23.516590</td>\n",
       "      <td>-6.842883</td>\n",
       "      <td>-16.082939</td>\n",
       "      <td>-12.801092</td>\n",
       "      <td>-19.576881</td>\n",
       "      <td>-5.197330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.959056</td>\n",
       "      <td>4.385456</td>\n",
       "      <td>3.423734</td>\n",
       "      <td>3.627139</td>\n",
       "      <td>4.857632</td>\n",
       "      <td>3.788988</td>\n",
       "      <td>4.757162</td>\n",
       "      <td>2.261868</td>\n",
       "      <td>4.300991</td>\n",
       "      <td>-0.573448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-705.806335</td>\n",
       "      <td>72.266678</td>\n",
       "      <td>5.647460</td>\n",
       "      <td>31.054544</td>\n",
       "      <td>2.051290</td>\n",
       "      <td>8.605760</td>\n",
       "      <td>-6.789633</td>\n",
       "      <td>4.041437</td>\n",
       "      <td>-0.349702</td>\n",
       "      <td>2.563606</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105547</td>\n",
       "      <td>-0.419525</td>\n",
       "      <td>1.316671</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>2.234987</td>\n",
       "      <td>-0.531794</td>\n",
       "      <td>-0.942795</td>\n",
       "      <td>-2.564018</td>\n",
       "      <td>-1.889065</td>\n",
       "      <td>0.181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4         5   \\\n",
       "0 -678.948853  76.402130  -3.969322  24.485060   2.343696  5.315933   \n",
       "1 -629.508362  54.859131 -15.076416  19.398994 -13.276542 -0.163535   \n",
       "2 -610.471497  60.676125  -6.567759  22.445854  -2.144975  2.539741   \n",
       "3 -632.858337  57.813908 -15.912763  11.742200 -23.516590 -6.842883   \n",
       "4 -705.806335  72.266678   5.647460  31.054544   2.051290  8.605760   \n",
       "\n",
       "          6          7          8         9   ...        30        31  \\\n",
       "0 -10.401676  -0.682352 -17.013817 -3.063685  ... -2.363485 -2.531532   \n",
       "1  -8.997267  -4.458826  -9.508459  0.139021  ...  5.524229  3.406778   \n",
       "2 -20.668135   0.123320  -7.860404 -4.285071  ... -1.345382 -2.634505   \n",
       "3 -16.082939 -12.801092 -19.576881 -5.197330  ...  1.959056  4.385456   \n",
       "4  -6.789633   4.041437  -0.349702  2.563606  ...  1.105547 -0.419525   \n",
       "\n",
       "         32        33        34        35        36        37        38  \\\n",
       "0 -1.793462 -4.022706 -1.577954 -1.587781 -1.696130 -2.855098 -3.651742   \n",
       "1  3.029715  3.747022  2.242086  2.204940 -1.960129 -1.560523 -0.784178   \n",
       "2 -2.230956 -0.879381 -1.582407 -1.810162 -3.177479 -5.062142 -3.402217   \n",
       "3  3.423734  3.627139  4.857632  3.788988  4.757162  2.261868  4.300991   \n",
       "4  1.316671  0.032284  2.234987 -0.531794 -0.942795 -2.564018 -1.889065   \n",
       "\n",
       "         39  \n",
       "0 -4.129297  \n",
       "1 -1.295257  \n",
       "2 -2.151505  \n",
       "3 -0.573448  \n",
       "4  0.181104  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_seperated = pd.DataFrame(df_features[\"features\"].values.tolist())\n",
    "df_feature_seperated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e637e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_feature_seperated\n",
    "df['emotions'] = df_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e77bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-678.948853</td>\n",
       "      <td>76.402130</td>\n",
       "      <td>-3.969322</td>\n",
       "      <td>24.485060</td>\n",
       "      <td>2.343696</td>\n",
       "      <td>5.315933</td>\n",
       "      <td>-10.401676</td>\n",
       "      <td>-0.682352</td>\n",
       "      <td>-17.013817</td>\n",
       "      <td>-3.063685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.531532</td>\n",
       "      <td>-1.793462</td>\n",
       "      <td>-4.022706</td>\n",
       "      <td>-1.577954</td>\n",
       "      <td>-1.587781</td>\n",
       "      <td>-1.696130</td>\n",
       "      <td>-2.855098</td>\n",
       "      <td>-3.651742</td>\n",
       "      <td>-4.129297</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-629.508362</td>\n",
       "      <td>54.859131</td>\n",
       "      <td>-15.076416</td>\n",
       "      <td>19.398994</td>\n",
       "      <td>-13.276542</td>\n",
       "      <td>-0.163535</td>\n",
       "      <td>-8.997267</td>\n",
       "      <td>-4.458826</td>\n",
       "      <td>-9.508459</td>\n",
       "      <td>0.139021</td>\n",
       "      <td>...</td>\n",
       "      <td>3.406778</td>\n",
       "      <td>3.029715</td>\n",
       "      <td>3.747022</td>\n",
       "      <td>2.242086</td>\n",
       "      <td>2.204940</td>\n",
       "      <td>-1.960129</td>\n",
       "      <td>-1.560523</td>\n",
       "      <td>-0.784178</td>\n",
       "      <td>-1.295257</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-610.471497</td>\n",
       "      <td>60.676125</td>\n",
       "      <td>-6.567759</td>\n",
       "      <td>22.445854</td>\n",
       "      <td>-2.144975</td>\n",
       "      <td>2.539741</td>\n",
       "      <td>-20.668135</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>-7.860404</td>\n",
       "      <td>-4.285071</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.634505</td>\n",
       "      <td>-2.230956</td>\n",
       "      <td>-0.879381</td>\n",
       "      <td>-1.582407</td>\n",
       "      <td>-1.810162</td>\n",
       "      <td>-3.177479</td>\n",
       "      <td>-5.062142</td>\n",
       "      <td>-3.402217</td>\n",
       "      <td>-2.151505</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-632.858337</td>\n",
       "      <td>57.813908</td>\n",
       "      <td>-15.912763</td>\n",
       "      <td>11.742200</td>\n",
       "      <td>-23.516590</td>\n",
       "      <td>-6.842883</td>\n",
       "      <td>-16.082939</td>\n",
       "      <td>-12.801092</td>\n",
       "      <td>-19.576881</td>\n",
       "      <td>-5.197330</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385456</td>\n",
       "      <td>3.423734</td>\n",
       "      <td>3.627139</td>\n",
       "      <td>4.857632</td>\n",
       "      <td>3.788988</td>\n",
       "      <td>4.757162</td>\n",
       "      <td>2.261868</td>\n",
       "      <td>4.300991</td>\n",
       "      <td>-0.573448</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-705.806335</td>\n",
       "      <td>72.266678</td>\n",
       "      <td>5.647460</td>\n",
       "      <td>31.054544</td>\n",
       "      <td>2.051290</td>\n",
       "      <td>8.605760</td>\n",
       "      <td>-6.789633</td>\n",
       "      <td>4.041437</td>\n",
       "      <td>-0.349702</td>\n",
       "      <td>2.563606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419525</td>\n",
       "      <td>1.316671</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>2.234987</td>\n",
       "      <td>-0.531794</td>\n",
       "      <td>-0.942795</td>\n",
       "      <td>-2.564018</td>\n",
       "      <td>-1.889065</td>\n",
       "      <td>0.181104</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-317.976044</td>\n",
       "      <td>9.312303</td>\n",
       "      <td>-30.541822</td>\n",
       "      <td>-4.778104</td>\n",
       "      <td>-18.936699</td>\n",
       "      <td>-14.217579</td>\n",
       "      <td>-18.650785</td>\n",
       "      <td>-14.171691</td>\n",
       "      <td>-10.407811</td>\n",
       "      <td>10.279816</td>\n",
       "      <td>...</td>\n",
       "      <td>2.892483</td>\n",
       "      <td>1.698947</td>\n",
       "      <td>-1.698887</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>-0.470242</td>\n",
       "      <td>1.039551</td>\n",
       "      <td>0.566789</td>\n",
       "      <td>0.088243</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>-466.040771</td>\n",
       "      <td>64.058754</td>\n",
       "      <td>-13.208256</td>\n",
       "      <td>18.619799</td>\n",
       "      <td>3.502764</td>\n",
       "      <td>-7.521268</td>\n",
       "      <td>-9.932314</td>\n",
       "      <td>0.287276</td>\n",
       "      <td>-22.124292</td>\n",
       "      <td>-2.246963</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.615298</td>\n",
       "      <td>-3.514129</td>\n",
       "      <td>-4.579769</td>\n",
       "      <td>-3.055513</td>\n",
       "      <td>-2.368344</td>\n",
       "      <td>-1.694364</td>\n",
       "      <td>-3.636990</td>\n",
       "      <td>-2.837501</td>\n",
       "      <td>-3.361457</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>-430.179443</td>\n",
       "      <td>21.672758</td>\n",
       "      <td>-33.558323</td>\n",
       "      <td>5.069038</td>\n",
       "      <td>-16.001268</td>\n",
       "      <td>-11.331733</td>\n",
       "      <td>-29.737926</td>\n",
       "      <td>-9.774052</td>\n",
       "      <td>-25.168562</td>\n",
       "      <td>-0.697188</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.243735</td>\n",
       "      <td>-3.616647</td>\n",
       "      <td>0.523052</td>\n",
       "      <td>0.894520</td>\n",
       "      <td>0.068520</td>\n",
       "      <td>1.921872</td>\n",
       "      <td>1.767919</td>\n",
       "      <td>-1.334365</td>\n",
       "      <td>-2.724165</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>-476.770508</td>\n",
       "      <td>57.986698</td>\n",
       "      <td>-17.799206</td>\n",
       "      <td>9.529842</td>\n",
       "      <td>-4.249583</td>\n",
       "      <td>-2.204914</td>\n",
       "      <td>-16.382473</td>\n",
       "      <td>-5.649986</td>\n",
       "      <td>-21.760571</td>\n",
       "      <td>-3.960779</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.068851</td>\n",
       "      <td>-1.858995</td>\n",
       "      <td>2.113119</td>\n",
       "      <td>3.029879</td>\n",
       "      <td>4.529030</td>\n",
       "      <td>5.874677</td>\n",
       "      <td>5.346369</td>\n",
       "      <td>4.791262</td>\n",
       "      <td>4.764572</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>-405.472229</td>\n",
       "      <td>10.349723</td>\n",
       "      <td>-35.471909</td>\n",
       "      <td>-11.647679</td>\n",
       "      <td>-20.851938</td>\n",
       "      <td>-14.179732</td>\n",
       "      <td>-26.196787</td>\n",
       "      <td>-13.691110</td>\n",
       "      <td>-21.874941</td>\n",
       "      <td>7.154139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>5.011798</td>\n",
       "      <td>2.444421</td>\n",
       "      <td>0.589064</td>\n",
       "      <td>-0.072291</td>\n",
       "      <td>-1.942562</td>\n",
       "      <td>0.371459</td>\n",
       "      <td>-1.415259</td>\n",
       "      <td>-1.228531</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "0   -678.948853  76.402130  -3.969322  24.485060   2.343696   5.315933   \n",
       "1   -629.508362  54.859131 -15.076416  19.398994 -13.276542  -0.163535   \n",
       "2   -610.471497  60.676125  -6.567759  22.445854  -2.144975   2.539741   \n",
       "3   -632.858337  57.813908 -15.912763  11.742200 -23.516590  -6.842883   \n",
       "4   -705.806335  72.266678   5.647460  31.054544   2.051290   8.605760   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "955 -317.976044   9.312303 -30.541822  -4.778104 -18.936699 -14.217579   \n",
       "956 -466.040771  64.058754 -13.208256  18.619799   3.502764  -7.521268   \n",
       "957 -430.179443  21.672758 -33.558323   5.069038 -16.001268 -11.331733   \n",
       "958 -476.770508  57.986698 -17.799206   9.529842  -4.249583  -2.204914   \n",
       "959 -405.472229  10.349723 -35.471909 -11.647679 -20.851938 -14.179732   \n",
       "\n",
       "             6          7          8          9  ...        31        32  \\\n",
       "0   -10.401676  -0.682352 -17.013817  -3.063685  ... -2.531532 -1.793462   \n",
       "1    -8.997267  -4.458826  -9.508459   0.139021  ...  3.406778  3.029715   \n",
       "2   -20.668135   0.123320  -7.860404  -4.285071  ... -2.634505 -2.230956   \n",
       "3   -16.082939 -12.801092 -19.576881  -5.197330  ...  4.385456  3.423734   \n",
       "4    -6.789633   4.041437  -0.349702   2.563606  ... -0.419525  1.316671   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "955 -18.650785 -14.171691 -10.407811  10.279816  ...  2.892483  1.698947   \n",
       "956  -9.932314   0.287276 -22.124292  -2.246963  ... -1.615298 -3.514129   \n",
       "957 -29.737926  -9.774052 -25.168562  -0.697188  ... -4.243735 -3.616647   \n",
       "958 -16.382473  -5.649986 -21.760571  -3.960779  ... -1.068851 -1.858995   \n",
       "959 -26.196787 -13.691110 -21.874941   7.154139  ...  0.920121  5.011798   \n",
       "\n",
       "           33        34        35        36        37        38        39  \\\n",
       "0   -4.022706 -1.577954 -1.587781 -1.696130 -2.855098 -3.651742 -4.129297   \n",
       "1    3.747022  2.242086  2.204940 -1.960129 -1.560523 -0.784178 -1.295257   \n",
       "2   -0.879381 -1.582407 -1.810162 -3.177479 -5.062142 -3.402217 -2.151505   \n",
       "3    3.627139  4.857632  3.788988  4.757162  2.261868  4.300991 -0.573448   \n",
       "4    0.032284  2.234987 -0.531794 -0.942795 -2.564018 -1.889065  0.181104   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "955 -1.698887  0.819549 -0.470242  1.039551  0.566789  0.088243  0.920238   \n",
       "956 -4.579769 -3.055513 -2.368344 -1.694364 -3.636990 -2.837501 -3.361457   \n",
       "957  0.523052  0.894520  0.068520  1.921872  1.767919 -1.334365 -2.724165   \n",
       "958  2.113119  3.029879  4.529030  5.874677  5.346369  4.791262  4.764572   \n",
       "959  2.444421  0.589064 -0.072291 -1.942562  0.371459 -1.415259 -1.228531   \n",
       "\n",
       "     emotions  \n",
       "0          02  \n",
       "1          02  \n",
       "2          02  \n",
       "3          02  \n",
       "4          02  \n",
       "..        ...  \n",
       "955        06  \n",
       "956        06  \n",
       "957        06  \n",
       "958        06  \n",
       "959        06  \n",
       "\n",
       "[960 rows x 41 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "609099c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the extracted features and emotions to csv file\n",
    "\n",
    "# df.to_csv(\"Audio_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa9bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import the data\n",
    "df = pd.read_csv(\"Audio_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a747528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-678.94885</td>\n",
       "      <td>76.402130</td>\n",
       "      <td>-3.969322</td>\n",
       "      <td>24.485060</td>\n",
       "      <td>2.343696</td>\n",
       "      <td>5.315933</td>\n",
       "      <td>-10.401676</td>\n",
       "      <td>-0.682352</td>\n",
       "      <td>-17.013817</td>\n",
       "      <td>-3.063685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.531532</td>\n",
       "      <td>-1.793462</td>\n",
       "      <td>-4.022706</td>\n",
       "      <td>-1.577954</td>\n",
       "      <td>-1.587781</td>\n",
       "      <td>-1.696130</td>\n",
       "      <td>-2.855098</td>\n",
       "      <td>-3.651741</td>\n",
       "      <td>-4.129297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-629.50836</td>\n",
       "      <td>54.859130</td>\n",
       "      <td>-15.076416</td>\n",
       "      <td>19.398994</td>\n",
       "      <td>-13.276542</td>\n",
       "      <td>-0.163535</td>\n",
       "      <td>-8.997267</td>\n",
       "      <td>-4.458826</td>\n",
       "      <td>-9.508459</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>...</td>\n",
       "      <td>3.406778</td>\n",
       "      <td>3.029715</td>\n",
       "      <td>3.747022</td>\n",
       "      <td>2.242086</td>\n",
       "      <td>2.204940</td>\n",
       "      <td>-1.960129</td>\n",
       "      <td>-1.560523</td>\n",
       "      <td>-0.784178</td>\n",
       "      <td>-1.295257</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-610.47150</td>\n",
       "      <td>60.676125</td>\n",
       "      <td>-6.567759</td>\n",
       "      <td>22.445854</td>\n",
       "      <td>-2.144975</td>\n",
       "      <td>2.539741</td>\n",
       "      <td>-20.668135</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>-7.860404</td>\n",
       "      <td>-4.285071</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.634505</td>\n",
       "      <td>-2.230956</td>\n",
       "      <td>-0.879381</td>\n",
       "      <td>-1.582407</td>\n",
       "      <td>-1.810162</td>\n",
       "      <td>-3.177479</td>\n",
       "      <td>-5.062142</td>\n",
       "      <td>-3.402217</td>\n",
       "      <td>-2.151505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-632.85834</td>\n",
       "      <td>57.813908</td>\n",
       "      <td>-15.912763</td>\n",
       "      <td>11.742200</td>\n",
       "      <td>-23.516590</td>\n",
       "      <td>-6.842883</td>\n",
       "      <td>-16.082940</td>\n",
       "      <td>-12.801092</td>\n",
       "      <td>-19.576881</td>\n",
       "      <td>-5.197330</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385456</td>\n",
       "      <td>3.423734</td>\n",
       "      <td>3.627139</td>\n",
       "      <td>4.857632</td>\n",
       "      <td>3.788988</td>\n",
       "      <td>4.757162</td>\n",
       "      <td>2.261868</td>\n",
       "      <td>4.300991</td>\n",
       "      <td>-0.573448</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-705.80634</td>\n",
       "      <td>72.266680</td>\n",
       "      <td>5.647461</td>\n",
       "      <td>31.054544</td>\n",
       "      <td>2.051290</td>\n",
       "      <td>8.605760</td>\n",
       "      <td>-6.789633</td>\n",
       "      <td>4.041437</td>\n",
       "      <td>-0.349702</td>\n",
       "      <td>2.563606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419525</td>\n",
       "      <td>1.316671</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>2.234987</td>\n",
       "      <td>-0.531794</td>\n",
       "      <td>-0.942795</td>\n",
       "      <td>-2.564018</td>\n",
       "      <td>-1.889065</td>\n",
       "      <td>0.181104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4         5          6  \\\n",
       "0 -678.94885  76.402130  -3.969322  24.485060   2.343696  5.315933 -10.401676   \n",
       "1 -629.50836  54.859130 -15.076416  19.398994 -13.276542 -0.163535  -8.997267   \n",
       "2 -610.47150  60.676125  -6.567759  22.445854  -2.144975  2.539741 -20.668135   \n",
       "3 -632.85834  57.813908 -15.912763  11.742200 -23.516590 -6.842883 -16.082940   \n",
       "4 -705.80634  72.266680   5.647461  31.054544   2.051290  8.605760  -6.789633   \n",
       "\n",
       "           7          8         9  ...        31        32        33  \\\n",
       "0  -0.682352 -17.013817 -3.063685  ... -2.531532 -1.793462 -4.022706   \n",
       "1  -4.458826  -9.508459  0.139020  ...  3.406778  3.029715  3.747022   \n",
       "2   0.123320  -7.860404 -4.285071  ... -2.634505 -2.230956 -0.879381   \n",
       "3 -12.801092 -19.576881 -5.197330  ...  4.385456  3.423734  3.627139   \n",
       "4   4.041437  -0.349702  2.563606  ... -0.419525  1.316671  0.032284   \n",
       "\n",
       "         34        35        36        37        38        39  emotions  \n",
       "0 -1.577954 -1.587781 -1.696130 -2.855098 -3.651741 -4.129297         2  \n",
       "1  2.242086  2.204940 -1.960129 -1.560523 -0.784178 -1.295257         2  \n",
       "2 -1.582407 -1.810162 -3.177479 -5.062142 -3.402217 -2.151505         2  \n",
       "3  4.857632  3.788988  4.757162  2.261868  4.300991 -0.573448         2  \n",
       "4  2.234987 -0.531794 -0.942795 -2.564018 -1.889065  0.181104         2  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed39d24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12ede438d60>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294d6a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "librosa.display.waveplot(np.array(df.loc[0]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a06cb",
   "metadata": {},
   "source": [
    "## Create Test and Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62377e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"emotions\", axis=1)\n",
    "y = df[\"emotions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8696f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-678.94885</td>\n",
       "      <td>76.402130</td>\n",
       "      <td>-3.969322</td>\n",
       "      <td>24.485060</td>\n",
       "      <td>2.343696</td>\n",
       "      <td>5.315933</td>\n",
       "      <td>-10.401676</td>\n",
       "      <td>-0.682352</td>\n",
       "      <td>-17.013817</td>\n",
       "      <td>-3.063685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.363485</td>\n",
       "      <td>-2.531532</td>\n",
       "      <td>-1.793462</td>\n",
       "      <td>-4.022706</td>\n",
       "      <td>-1.577954</td>\n",
       "      <td>-1.587781</td>\n",
       "      <td>-1.696130</td>\n",
       "      <td>-2.855098</td>\n",
       "      <td>-3.651741</td>\n",
       "      <td>-4.129297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-629.50836</td>\n",
       "      <td>54.859130</td>\n",
       "      <td>-15.076416</td>\n",
       "      <td>19.398994</td>\n",
       "      <td>-13.276542</td>\n",
       "      <td>-0.163535</td>\n",
       "      <td>-8.997267</td>\n",
       "      <td>-4.458826</td>\n",
       "      <td>-9.508459</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>...</td>\n",
       "      <td>5.524229</td>\n",
       "      <td>3.406778</td>\n",
       "      <td>3.029715</td>\n",
       "      <td>3.747022</td>\n",
       "      <td>2.242086</td>\n",
       "      <td>2.204940</td>\n",
       "      <td>-1.960129</td>\n",
       "      <td>-1.560523</td>\n",
       "      <td>-0.784178</td>\n",
       "      <td>-1.295257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-610.47150</td>\n",
       "      <td>60.676125</td>\n",
       "      <td>-6.567759</td>\n",
       "      <td>22.445854</td>\n",
       "      <td>-2.144975</td>\n",
       "      <td>2.539741</td>\n",
       "      <td>-20.668135</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>-7.860404</td>\n",
       "      <td>-4.285071</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.345382</td>\n",
       "      <td>-2.634505</td>\n",
       "      <td>-2.230956</td>\n",
       "      <td>-0.879381</td>\n",
       "      <td>-1.582407</td>\n",
       "      <td>-1.810162</td>\n",
       "      <td>-3.177479</td>\n",
       "      <td>-5.062142</td>\n",
       "      <td>-3.402217</td>\n",
       "      <td>-2.151505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-632.85834</td>\n",
       "      <td>57.813908</td>\n",
       "      <td>-15.912763</td>\n",
       "      <td>11.742200</td>\n",
       "      <td>-23.516590</td>\n",
       "      <td>-6.842883</td>\n",
       "      <td>-16.082940</td>\n",
       "      <td>-12.801092</td>\n",
       "      <td>-19.576881</td>\n",
       "      <td>-5.197330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.959056</td>\n",
       "      <td>4.385456</td>\n",
       "      <td>3.423734</td>\n",
       "      <td>3.627139</td>\n",
       "      <td>4.857632</td>\n",
       "      <td>3.788988</td>\n",
       "      <td>4.757162</td>\n",
       "      <td>2.261868</td>\n",
       "      <td>4.300991</td>\n",
       "      <td>-0.573448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-705.80634</td>\n",
       "      <td>72.266680</td>\n",
       "      <td>5.647461</td>\n",
       "      <td>31.054544</td>\n",
       "      <td>2.051290</td>\n",
       "      <td>8.605760</td>\n",
       "      <td>-6.789633</td>\n",
       "      <td>4.041437</td>\n",
       "      <td>-0.349702</td>\n",
       "      <td>2.563606</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105547</td>\n",
       "      <td>-0.419525</td>\n",
       "      <td>1.316671</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>2.234987</td>\n",
       "      <td>-0.531794</td>\n",
       "      <td>-0.942795</td>\n",
       "      <td>-2.564018</td>\n",
       "      <td>-1.889065</td>\n",
       "      <td>0.181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4         5          6  \\\n",
       "0 -678.94885  76.402130  -3.969322  24.485060   2.343696  5.315933 -10.401676   \n",
       "1 -629.50836  54.859130 -15.076416  19.398994 -13.276542 -0.163535  -8.997267   \n",
       "2 -610.47150  60.676125  -6.567759  22.445854  -2.144975  2.539741 -20.668135   \n",
       "3 -632.85834  57.813908 -15.912763  11.742200 -23.516590 -6.842883 -16.082940   \n",
       "4 -705.80634  72.266680   5.647461  31.054544   2.051290  8.605760  -6.789633   \n",
       "\n",
       "           7          8         9  ...        30        31        32  \\\n",
       "0  -0.682352 -17.013817 -3.063685  ... -2.363485 -2.531532 -1.793462   \n",
       "1  -4.458826  -9.508459  0.139020  ...  5.524229  3.406778  3.029715   \n",
       "2   0.123320  -7.860404 -4.285071  ... -1.345382 -2.634505 -2.230956   \n",
       "3 -12.801092 -19.576881 -5.197330  ...  1.959056  4.385456  3.423734   \n",
       "4   4.041437  -0.349702  2.563606  ...  1.105547 -0.419525  1.316671   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0 -4.022706 -1.577954 -1.587781 -1.696130 -2.855098 -3.651741 -4.129297  \n",
       "1  3.747022  2.242086  2.204940 -1.960129 -1.560523 -0.784178 -1.295257  \n",
       "2 -0.879381 -1.582407 -1.810162 -3.177479 -5.062142 -3.402217 -2.151505  \n",
       "3  3.627139  4.857632  3.788988  4.757162  2.261868  4.300991 -0.573448  \n",
       "4  0.032284  2.234987 -0.531794 -0.942795 -2.564018 -1.889065  0.181104  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a904e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: emotions, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79eeb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437de7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-678.94885</td>\n",
       "      <td>76.402130</td>\n",
       "      <td>-3.969322</td>\n",
       "      <td>24.485060</td>\n",
       "      <td>2.343696</td>\n",
       "      <td>5.315933</td>\n",
       "      <td>-10.401676</td>\n",
       "      <td>-0.682352</td>\n",
       "      <td>-17.013817</td>\n",
       "      <td>-3.063685</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.363485</td>\n",
       "      <td>-2.531532</td>\n",
       "      <td>-1.793462</td>\n",
       "      <td>-4.022706</td>\n",
       "      <td>-1.577954</td>\n",
       "      <td>-1.587781</td>\n",
       "      <td>-1.696130</td>\n",
       "      <td>-2.855098</td>\n",
       "      <td>-3.651741</td>\n",
       "      <td>-4.129297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-629.50836</td>\n",
       "      <td>54.859130</td>\n",
       "      <td>-15.076416</td>\n",
       "      <td>19.398994</td>\n",
       "      <td>-13.276542</td>\n",
       "      <td>-0.163535</td>\n",
       "      <td>-8.997267</td>\n",
       "      <td>-4.458826</td>\n",
       "      <td>-9.508459</td>\n",
       "      <td>0.139020</td>\n",
       "      <td>...</td>\n",
       "      <td>5.524229</td>\n",
       "      <td>3.406778</td>\n",
       "      <td>3.029715</td>\n",
       "      <td>3.747022</td>\n",
       "      <td>2.242086</td>\n",
       "      <td>2.204940</td>\n",
       "      <td>-1.960129</td>\n",
       "      <td>-1.560523</td>\n",
       "      <td>-0.784178</td>\n",
       "      <td>-1.295257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-610.47150</td>\n",
       "      <td>60.676125</td>\n",
       "      <td>-6.567759</td>\n",
       "      <td>22.445854</td>\n",
       "      <td>-2.144975</td>\n",
       "      <td>2.539741</td>\n",
       "      <td>-20.668135</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>-7.860404</td>\n",
       "      <td>-4.285071</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.345382</td>\n",
       "      <td>-2.634505</td>\n",
       "      <td>-2.230956</td>\n",
       "      <td>-0.879381</td>\n",
       "      <td>-1.582407</td>\n",
       "      <td>-1.810162</td>\n",
       "      <td>-3.177479</td>\n",
       "      <td>-5.062142</td>\n",
       "      <td>-3.402217</td>\n",
       "      <td>-2.151505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-632.85834</td>\n",
       "      <td>57.813908</td>\n",
       "      <td>-15.912763</td>\n",
       "      <td>11.742200</td>\n",
       "      <td>-23.516590</td>\n",
       "      <td>-6.842883</td>\n",
       "      <td>-16.082940</td>\n",
       "      <td>-12.801092</td>\n",
       "      <td>-19.576881</td>\n",
       "      <td>-5.197330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.959056</td>\n",
       "      <td>4.385456</td>\n",
       "      <td>3.423734</td>\n",
       "      <td>3.627139</td>\n",
       "      <td>4.857632</td>\n",
       "      <td>3.788988</td>\n",
       "      <td>4.757162</td>\n",
       "      <td>2.261868</td>\n",
       "      <td>4.300991</td>\n",
       "      <td>-0.573448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-705.80634</td>\n",
       "      <td>72.266680</td>\n",
       "      <td>5.647461</td>\n",
       "      <td>31.054544</td>\n",
       "      <td>2.051290</td>\n",
       "      <td>8.605760</td>\n",
       "      <td>-6.789633</td>\n",
       "      <td>4.041437</td>\n",
       "      <td>-0.349702</td>\n",
       "      <td>2.563606</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105547</td>\n",
       "      <td>-0.419525</td>\n",
       "      <td>1.316671</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>2.234987</td>\n",
       "      <td>-0.531794</td>\n",
       "      <td>-0.942795</td>\n",
       "      <td>-2.564018</td>\n",
       "      <td>-1.889065</td>\n",
       "      <td>0.181104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4         5          6  \\\n",
       "0 -678.94885  76.402130  -3.969322  24.485060   2.343696  5.315933 -10.401676   \n",
       "1 -629.50836  54.859130 -15.076416  19.398994 -13.276542 -0.163535  -8.997267   \n",
       "2 -610.47150  60.676125  -6.567759  22.445854  -2.144975  2.539741 -20.668135   \n",
       "3 -632.85834  57.813908 -15.912763  11.742200 -23.516590 -6.842883 -16.082940   \n",
       "4 -705.80634  72.266680   5.647461  31.054544   2.051290  8.605760  -6.789633   \n",
       "\n",
       "           7          8         9  ...        30        31        32  \\\n",
       "0  -0.682352 -17.013817 -3.063685  ... -2.363485 -2.531532 -1.793462   \n",
       "1  -4.458826  -9.508459  0.139020  ...  5.524229  3.406778  3.029715   \n",
       "2   0.123320  -7.860404 -4.285071  ... -1.345382 -2.634505 -2.230956   \n",
       "3 -12.801092 -19.576881 -5.197330  ...  1.959056  4.385456  3.423734   \n",
       "4   4.041437  -0.349702  2.563606  ...  1.105547 -0.419525  1.316671   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0 -4.022706 -1.577954 -1.587781 -1.696130 -2.855098 -3.651741 -4.129297  \n",
       "1  3.747022  2.242086  2.204940 -1.960129 -1.560523 -0.784178 -1.295257  \n",
       "2 -0.879381 -1.582407 -1.810162 -3.177479 -5.062142 -3.402217 -2.151505  \n",
       "3  3.627139  4.857632  3.788988  4.757162  2.261868  4.300991 -0.573448  \n",
       "4  0.032284  2.234987 -0.531794 -0.942795 -2.564018 -1.889065  0.181104  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63e39ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c520fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c9df3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a33e100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 40), (192, 40), (768, 5), (192, 5))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d16af1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df0c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape\n",
    "X.loc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b236af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75a3d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 40, 256)           1536      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 40, 256)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 40, 128)           163968    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 40, 128)           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 5, 128)            82048     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5, 128)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 5, 128)            82048     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5, 128)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 640)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 3205      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,805\n",
      "Trainable params: 332,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "783f248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb665d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0103 - accuracy: 0.9926\n",
      "Epoch 00001: val_loss improved from inf to 2.14599, saving model to ./saveModel\\audio_classification.hdf5\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9935 - val_loss: 2.1460 - val_accuracy: 0.6615\n",
      "Epoch 2/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0166 - accuracy: 0.9911\n",
      "Epoch 00002: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0154 - accuracy: 0.9922 - val_loss: 2.1675 - val_accuracy: 0.6562\n",
      "Epoch 3/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 00003: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 2.3484 - val_accuracy: 0.6510\n",
      "Epoch 4/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00004: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 2.3604 - val_accuracy: 0.6823\n",
      "Epoch 5/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00005: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3322 - val_accuracy: 0.6719\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00006: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4178 - val_accuracy: 0.6875\n",
      "Epoch 7/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 8.8949e-04 - accuracy: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.1019e-04 - accuracy: 1.0000 - val_loss: 2.3068 - val_accuracy: 0.6875\n",
      "Epoch 8/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0054 - accuracy: 0.9970\n",
      "Epoch 00008: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 2.3073 - val_accuracy: 0.6771\n",
      "Epoch 9/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00009: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3847 - val_accuracy: 0.6719\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00010: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4097 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 2.1673e-04 - accuracy: 1.0000\n",
      "Epoch 00011: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.2281e-04 - accuracy: 1.0000 - val_loss: 2.4061 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00012: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.3359 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 4.7730e-04 - accuracy: 1.0000\n",
      "Epoch 00013: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 5.8340e-04 - accuracy: 1.0000 - val_loss: 2.3017 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.8090e-04 - accuracy: 1.0000\n",
      "Epoch 00014: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8090e-04 - accuracy: 1.0000 - val_loss: 2.3193 - val_accuracy: 0.6823\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9974  \n",
      "Epoch 00015: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 0.9974 - val_loss: 2.4264 - val_accuracy: 0.6510\n",
      "Epoch 16/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985    \n",
      "Epoch 00016: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.3506 - val_accuracy: 0.6719\n",
      "Epoch 17/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00017: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 2.5558 - val_accuracy: 0.6562\n",
      "Epoch 18/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0046 - accuracy: 0.9970\n",
      "Epoch 00018: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 2.4356 - val_accuracy: 0.6719\n",
      "Epoch 19/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985    \n",
      "Epoch 00019: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 2.6225 - val_accuracy: 0.6510\n",
      "Epoch 20/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0114 - accuracy: 0.9929\n",
      "Epoch 00020: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0190 - accuracy: 0.9922 - val_loss: 2.6853 - val_accuracy: 0.6406\n",
      "Epoch 21/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0313 - accuracy: 0.9957\n",
      "Epoch 00021: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0302 - accuracy: 0.9948 - val_loss: 2.3495 - val_accuracy: 0.6615\n",
      "Epoch 22/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0195 - accuracy: 0.9955\n",
      "Epoch 00022: val_loss did not improve from 2.14599\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 2.5601 - val_accuracy: 0.6771\n",
      "Epoch 23/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0282 - accuracy: 0.9918\n",
      "Epoch 00023: val_loss improved from 2.14599 to 2.08111, saving model to ./saveModel\\audio_classification.hdf5\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 2.0811 - val_accuracy: 0.6458\n",
      "Epoch 24/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0687 - accuracy: 0.9796\n",
      "Epoch 00024: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0662 - accuracy: 0.9805 - val_loss: 2.6059 - val_accuracy: 0.6094\n",
      "Epoch 25/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0275 - accuracy: 0.9896\n",
      "Epoch 00025: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 2.3376 - val_accuracy: 0.6354\n",
      "Epoch 26/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0429 - accuracy: 0.9891\n",
      "Epoch 00026: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9896 - val_loss: 2.7131 - val_accuracy: 0.6094\n",
      "Epoch 27/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0324 - accuracy: 0.9836\n",
      "Epoch 00027: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9818 - val_loss: 2.2581 - val_accuracy: 0.6562\n",
      "Epoch 28/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0457 - accuracy: 0.9836\n",
      "Epoch 00028: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0537 - accuracy: 0.9792 - val_loss: 3.1052 - val_accuracy: 0.6094\n",
      "Epoch 29/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1387 - accuracy: 0.9660\n",
      "Epoch 00029: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 0.1393 - accuracy: 0.9661 - val_loss: 2.4540 - val_accuracy: 0.6406\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1450 - accuracy: 0.9552\n",
      "Epoch 00030: val_loss did not improve from 2.08111\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.1412 - accuracy: 0.9557 - val_loss: 2.2646 - val_accuracy: 0.6146\n",
      "Epoch 31/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0749 - accuracy: 0.9717\n",
      "Epoch 00031: val_loss improved from 2.08111 to 1.98515, saving model to ./saveModel\\audio_classification.hdf5\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 1.9851 - val_accuracy: 0.6615\n",
      "Epoch 32/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0450 - accuracy: 0.9872\n",
      "Epoch 00032: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 2.4487 - val_accuracy: 0.6302\n",
      "Epoch 33/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0322 - accuracy: 0.9881\n",
      "Epoch 00033: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0305 - accuracy: 0.9883 - val_loss: 2.5653 - val_accuracy: 0.6562\n",
      "Epoch 34/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9864\n",
      "Epoch 00034: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0371 - accuracy: 0.9870 - val_loss: 2.1870 - val_accuracy: 0.6562\n",
      "Epoch 35/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0212 - accuracy: 0.9940\n",
      "Epoch 00035: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 2.2291 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0262 - accuracy: 0.9891\n",
      "Epoch 00036: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 2.1178 - val_accuracy: 0.6823\n",
      "Epoch 37/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0599 - accuracy: 0.9836\n",
      "Epoch 00037: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0532 - accuracy: 0.9857 - val_loss: 2.2253 - val_accuracy: 0.6510\n",
      "Epoch 38/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0691 - accuracy: 0.9807\n",
      "Epoch 00038: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0633 - accuracy: 0.9818 - val_loss: 2.6343 - val_accuracy: 0.6094\n",
      "Epoch 39/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0604 - accuracy: 0.9792\n",
      "Epoch 00039: val_loss did not improve from 1.98515\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0649 - accuracy: 0.9753 - val_loss: 2.1871 - val_accuracy: 0.6615\n",
      "Epoch 40/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0133 - accuracy: 0.9973\n",
      "Epoch 00040: val_loss improved from 1.98515 to 1.88908, saving model to ./saveModel\\audio_classification.hdf5\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 1.8891 - val_accuracy: 0.6823\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 00041: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 1.9031 - val_accuracy: 0.7083\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000  \n",
      "Epoch 00042: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0432 - val_accuracy: 0.6823\n",
      "Epoch 43/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 7.4779e-04 - accuracy: 1.0000 ETA: 0s - loss: 8.0016e-04 - \n",
      "Epoch 00043: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 7.2288e-04 - accuracy: 1.0000 - val_loss: 2.1021 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 5.7680e-04 - accuracy: 1.0000\n",
      "Epoch 00044: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 5.7680e-04 - accuracy: 1.0000 - val_loss: 2.0261 - val_accuracy: 0.6771\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 5.7121e-04 - accuracy: 1.0000\n",
      "Epoch 00045: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.7121e-04 - accuracy: 1.0000 - val_loss: 2.0404 - val_accuracy: 0.6875\n",
      "Epoch 46/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 8.7026e-04 - accuracy: 1.0000\n",
      "Epoch 00046: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 7.9094e-04 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.6927\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 9.4799e-04 - accuracy: 1.0000\n",
      "Epoch 00047: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.4799e-04 - accuracy: 1.0000 - val_loss: 1.9347 - val_accuracy: 0.7031\n",
      "Epoch 48/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0072 - accuracy: 0.9970\n",
      "Epoch 00048: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 2.0029 - val_accuracy: 0.7188\n",
      "Epoch 49/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 00049: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 2.2853 - val_accuracy: 0.6562\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 00050: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.9924 - val_accuracy: 0.7188\n",
      "Epoch 51/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00051: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9650 - val_accuracy: 0.6979\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 5.2738e-04 - accuracy: 1.0000\n",
      "Epoch 00052: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.2738e-04 - accuracy: 1.0000 - val_loss: 1.9866 - val_accuracy: 0.6771\n",
      "Epoch 53/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 3.2107e-04 - accuracy: 1.0000\n",
      "Epoch 00053: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.4980e-04 - accuracy: 1.0000 - val_loss: 1.9888 - val_accuracy: 0.6771\n",
      "Epoch 54/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 1.9510e-04 - accuracy: 1.0000\n",
      "Epoch 00054: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2489e-04 - accuracy: 1.0000 - val_loss: 1.9852 - val_accuracy: 0.6875\n",
      "Epoch 55/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 2.8192e-04 - accuracy: 1.0000\n",
      "Epoch 00055: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.8542e-04 - accuracy: 1.0000 - val_loss: 2.0063 - val_accuracy: 0.6875\n",
      "Epoch 56/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 5.2841e-04 - accuracy: 1.0000\n",
      "Epoch 00056: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 5.0957e-04 - accuracy: 1.0000 - val_loss: 1.9547 - val_accuracy: 0.6979\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
      "Epoch 00057: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0240 - val_accuracy: 0.6927\n",
      "Epoch 58/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 4.8731e-04 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 4.6864e-04 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.6979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 3.6212e-04 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 3.6212e-04 - accuracy: 1.0000 - val_loss: 2.0738 - val_accuracy: 0.6979\n",
      "Epoch 60/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 00060: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0343 - val_accuracy: 0.7135\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 2.2362e-04 - accuracy: 1.0000\n",
      "Epoch 00061: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2362e-04 - accuracy: 1.0000 - val_loss: 2.0728 - val_accuracy: 0.7188\n",
      "Epoch 62/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 8.5802e-04 - accuracy: 1.0000\n",
      "Epoch 00062: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 8.2575e-04 - accuracy: 1.0000 - val_loss: 2.1152 - val_accuracy: 0.7135\n",
      "Epoch 63/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 8.2017e-04 - accuracy: 1.0000\n",
      "Epoch 00063: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.3965e-04 - accuracy: 1.0000 - val_loss: 2.2209 - val_accuracy: 0.7083\n",
      "Epoch 64/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 8.3777e-04 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 8.0838e-04 - accuracy: 1.0000 - val_loss: 2.2387 - val_accuracy: 0.7083\n",
      "Epoch 65/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 7.0520e-04 - accuracy: 1.0000\n",
      "Epoch 00065: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.2402e-04 - accuracy: 1.0000 - val_loss: 2.1276 - val_accuracy: 0.7188\n",
      "Epoch 66/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 2.5686e-04 - accuracy: 1.0000\n",
      "Epoch 00066: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.3386e-04 - accuracy: 1.0000 - val_loss: 2.1398 - val_accuracy: 0.7240\n",
      "Epoch 67/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0023 - accuracy: 0.9985  \n",
      "Epoch 00067: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.9974 - val_loss: 2.4674 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9961\n",
      "Epoch 00068: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0256 - accuracy: 0.9961 - val_loss: 2.2735 - val_accuracy: 0.6354\n",
      "Epoch 69/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0296 - accuracy: 0.9932\n",
      "Epoch 00069: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 2.2205 - val_accuracy: 0.6458\n",
      "Epoch 70/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0319 - accuracy: 0.9896\n",
      "Epoch 00070: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 2.6975 - val_accuracy: 0.6198\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9922\n",
      "Epoch 00071: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 2.3449 - val_accuracy: 0.6458\n",
      "Epoch 72/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0235 - accuracy: 0.9915\n",
      "Epoch 00072: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 2.2115 - val_accuracy: 0.6146\n",
      "Epoch 73/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0195 - accuracy: 0.9901\n",
      "Epoch 00073: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 0.0203 - accuracy: 0.9896 - val_loss: 2.4719 - val_accuracy: 0.6406\n",
      "Epoch 74/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0300 - accuracy: 0.9891\n",
      "Epoch 00074: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 2.5927 - val_accuracy: 0.5781\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9779\n",
      "Epoch 00075: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0711 - accuracy: 0.9779 - val_loss: 2.9750 - val_accuracy: 0.6094\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9544\n",
      "Epoch 00076: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 0.1759 - accuracy: 0.9544 - val_loss: 2.7122 - val_accuracy: 0.5417\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9583\n",
      "Epoch 00077: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 0.1612 - accuracy: 0.9583 - val_loss: 2.5192 - val_accuracy: 0.5625\n",
      "Epoch 78/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0951 - accuracy: 0.9702\n",
      "Epoch 00078: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 2.4906 - val_accuracy: 0.5781\n",
      "Epoch 79/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0738 - accuracy: 0.9881\n",
      "Epoch 00079: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0702 - accuracy: 0.9857 - val_loss: 2.0055 - val_accuracy: 0.6302\n",
      "Epoch 80/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0243 - accuracy: 0.9915\n",
      "Epoch 00080: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 2.5953 - val_accuracy: 0.6354\n",
      "Epoch 81/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0139 - accuracy: 0.9940\n",
      "Epoch 00081: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 2.4291 - val_accuracy: 0.6146\n",
      "Epoch 82/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972\n",
      "Epoch 00082: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 2.3446 - val_accuracy: 0.6198\n",
      "Epoch 83/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0070 - accuracy: 0.9957\n",
      "Epoch 00083: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 0.9948 - val_loss: 2.3564 - val_accuracy: 0.6510\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9948\n",
      "Epoch 00084: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 2.7124 - val_accuracy: 0.6562\n",
      "Epoch 85/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0191 - accuracy: 0.9955\n",
      "Epoch 00085: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 2.6709 - val_accuracy: 0.6250\n",
      "Epoch 86/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0420 - accuracy: 0.9901\n",
      "Epoch 00086: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0387 - accuracy: 0.9909 - val_loss: 2.4138 - val_accuracy: 0.6354\n",
      "Epoch 87/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0309 - accuracy: 0.9918\n",
      "Epoch 00087: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0296 - accuracy: 0.9922 - val_loss: 2.1925 - val_accuracy: 0.6458\n",
      "Epoch 88/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0365 - accuracy: 0.9915\n",
      "Epoch 00088: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: 2.0978 - val_accuracy: 0.6823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 00089: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 2.1013 - val_accuracy: 0.6875\n",
      "Epoch 90/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.0520 - val_accuracy: 0.6615\n",
      "Epoch 91/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 2.0327 - val_accuracy: 0.6875\n",
      "Epoch 92/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0138 - accuracy: 0.9946\n",
      "Epoch 00092: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0151 - accuracy: 0.9935 - val_loss: 2.1192 - val_accuracy: 0.6615\n",
      "Epoch 93/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0267 - accuracy: 0.9929\n",
      "Epoch 00093: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 2.2101 - val_accuracy: 0.6771\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 00094: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 2.3191 - val_accuracy: 0.6927\n",
      "Epoch 95/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2949 - val_accuracy: 0.7031\n",
      "Epoch 96/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.2902 - val_accuracy: 0.6927\n",
      "Epoch 97/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.2565 - val_accuracy: 0.6719\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9987  \n",
      "Epoch 00098: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 2.1732 - val_accuracy: 0.6510\n",
      "Epoch 99/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0230 - accuracy: 0.9986\n",
      "Epoch 00099: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0221 - accuracy: 0.9987 - val_loss: 2.1053 - val_accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 1.88908\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.1556 - val_accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ee05c8310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "checkpointer = ModelCheckpoint(filepath='./saveModel/audio_classification.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bc2f4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510416865348816"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "test_accuracy[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50d793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
